{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clears solution dir\n",
    "import os, shutil\n",
    "folder = './solutions'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7198ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clears solution_organized dir\n",
    "import os, shutil\n",
    "folder = './solutions_organized'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ac43b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#checks reason for not completed problems\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load and deduplicate problem names\n",
    "nc_file = \"not_completed/not_completed_problems.txt\"\n",
    "with open(nc_file, \"r\") as f:\n",
    "    nc_problem_names = list(set(line.strip() for line in f))\n",
    "\n",
    "print(f\"Total unique not-completed problems: {len(nc_problem_names)}\")\n",
    "\n",
    "solutions_path = \"solutions\"\n",
    "\n",
    "# Time thresholds and tolerance\n",
    "timeout_thresholds = [3600, 7200]\n",
    "tolerance = 5  # seconds\n",
    "\n",
    "# Results\n",
    "problems_out_of_time = []\n",
    "problems_with_no_solution = []\n",
    "problems_with_missing_output = []\n",
    "\n",
    "for problem in nc_problem_names:\n",
    "    problem_file = os.path.join(solutions_path, f\"{problem}_output.sas\")\n",
    "\n",
    "    if not os.path.exists(problem_file):\n",
    "        print(f\"[MISSING] {problem} has no output file.\")\n",
    "        problems_with_missing_output.append(problem)\n",
    "        continue\n",
    "\n",
    "    with open(problem_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if not lines:\n",
    "        print(f\"[EMPTY] {problem} output file is empty.\")\n",
    "        problems_with_no_solution.append(problem)\n",
    "        continue\n",
    "\n",
    "    last_line = lines[-1].strip()\n",
    "    match = re.search(r'Time taken: (\\d+(?:\\.\\d+)?)', last_line)\n",
    "\n",
    "    if match:\n",
    "        time_taken = float(match.group(1))\n",
    "\n",
    "        # Check if time_taken is close to any timeout threshold\n",
    "        if any(abs(time_taken - threshold) <= tolerance for threshold in timeout_thresholds):\n",
    "            problems_out_of_time.append(problem)\n",
    "            print(f\"[TIMEOUT] {problem}: {time_taken} seconds (within timeout window)\")\n",
    "        else:\n",
    "            problems_with_no_solution.append(problem)\n",
    "            print(f\"[NO SOLUTION] {problem}: {time_taken} seconds (not near timeout)\")\n",
    "    else:\n",
    "        print(f\"[NO TIME INFO] {problem}: 'Time taken' not found.\")\n",
    "        problems_with_no_solution.append(problem)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Problems out of time (~{timeout_thresholds}Â±{tolerance}s): {len(problems_out_of_time)}\")\n",
    "print(f\"Problems with no solution: {len(problems_with_no_solution)}\")\n",
    "print(f\"Problems with missing output file: {len(problems_with_missing_output)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a problem name find the corresponding logs in the log folder and print them\n",
    "\n",
    "import os\n",
    "import re\n",
    "problem_name = \"p020244_2\"  # Example problem name\n",
    "logs_folder = \"logs\"\n",
    "pattern = re.compile(r'^logs_script_\\d+_plan\\{(?P<problem>[^}]+)\\.pddl\\}(?P<err>\\.err)?\\.txt$')\n",
    "\n",
    "for fname in os.listdir(logs_folder):\n",
    "    if pattern.match(fname):\n",
    "        match = pattern.match(fname)\n",
    "        if match.group(\"problem\") == problem_name:\n",
    "            with open(os.path.join(logs_folder, fname), 'r') as f:\n",
    "                content = f.read()\n",
    "                print(f\"----------------------\\nLog file: {fname}\\nContent:\\n{content}\\n\")\n",
    "else:\n",
    "    print(f\"----------------\\nFinished searching for logs related to problem: {problem_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd415c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts completed FULL PROBLEMS (Have .SOL file for all versions)\n",
    "import os\n",
    "\n",
    "solutions_path = \"solutions\"\n",
    "completed_dict = {}\n",
    "total_count_plans = 0\n",
    "for file in os.listdir(solutions_path):\n",
    "    if file.endswith(\".SOL\"):\n",
    "        name = file.split(\"_\")[0]\n",
    "        if not (name in completed_dict):\n",
    "            completed_dict[name] = 0\n",
    "        completed_dict[name] += 1\n",
    "        total_count_plans += 1\n",
    "\n",
    "completed_count = 0\n",
    "not_completed_count = 0\n",
    "for key, val in completed_dict.items():\n",
    "    if val >= 5:\n",
    "        completed_count += 1\n",
    "    else:\n",
    "        # print(f\"Problem: {key}, is NOT completed ({val}/5)\")\n",
    "        not_completed_count += 1\n",
    "\n",
    "print(\"FULL PROBLEMS: \", completed_count)\n",
    "print(\"NOT FULL PROBLEMS: \", not_completed_count)\n",
    "print(\"TOTAL PLANS WITH SOL: \", total_count_plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copies original solutions to the solutions folder\n",
    "import os\n",
    "import shutil\n",
    "solutions_folder = './solutions'\n",
    "og_solutions_folder = './og_solutions'\n",
    "\n",
    "for sol_file in os.listdir(og_solutions_folder):\n",
    "    target_path = os.path.join(solutions_folder, f\"{sol_file.split(\".\")[0]}_og.SOL\")\n",
    "    shutil.copy(sol_file, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94852ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizes solutions into a structured directory based on problem completeness\n",
    "# It copies .SOL and .sas files for problems that have at least 5 solutions into a new directory structure. \n",
    "# todo we dont need all versions for each file, even just one is ok\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "solutions_folder = './solutions'\n",
    "target_sol_folder = './solutions_organized'\n",
    "\n",
    "# Identify full problems based on having at least 6 .SOL files\n",
    "completed_dict = {}\n",
    "for file in os.listdir(solutions_folder):\n",
    "    if file.endswith(\".SOL\"):\n",
    "        problem = file.split(\".\")[0]\n",
    "        if \"_\" in problem:\n",
    "            problem = file.split(\"_\")[0]\n",
    "        completed_dict[problem] = completed_dict.get(problem, 0) + 1\n",
    "\n",
    "full_problems = {problem for problem, cnt in completed_dict.items() if cnt == 6}\n",
    "print(\"Full problems:\", len(full_problems))\n",
    "\n",
    "# Regex to match files like p123456_0.SOL or p123456_1.sas (case-insensitive)\n",
    "pattern = re.compile(r'^(?P<problem>p\\d+)_(\\d+|og).*\\.?(?P<ext>SOL|sas)$', re.IGNORECASE)\n",
    "\n",
    "# Loop through all files in the solutions folder and copy only those for full problems\n",
    "for filename in os.listdir(solutions_folder):\n",
    "    file_path = os.path.join(solutions_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            problem = match.group(\"problem\")\n",
    "            if problem in full_problems:\n",
    "                ext = match.group(\"ext\").lower()  # normalize extension to lower-case\n",
    "                # Set target subdirectory based on file extension\n",
    "                if ext == \"sol\":\n",
    "                    subfolder = \"sols\"\n",
    "                elif ext == \"sas\":\n",
    "                    subfolder = \"sas\"\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Construct directory paths\n",
    "                problem_folder = os.path.join(target_sol_folder, problem)\n",
    "                target_folder = os.path.join(problem_folder, subfolder)\n",
    "                os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "                # Build target file path and copy file\n",
    "                target_file = os.path.join(target_folder, filename)\n",
    "                # print(f\"Copying {filename} to {target_file}\")\n",
    "                shutil.copy(file_path, target_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clears empty .sas coming from wrong pddls or aborted executions that dont end in error\n",
    "\n",
    "import os\n",
    "folder = './solutions'\n",
    "\n",
    "files_to_remove = []\n",
    "file_good = []\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    if file_path.endswith(\".sas\"):\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            file.close()\n",
    "        if lines[0].startswith(\"Time\"): # indicates that no steps were executed\n",
    "            files_to_remove.append(file_path)\n",
    "        else:\n",
    "            file_good.append(file_path)\n",
    "    \n",
    "for file in files_to_remove:\n",
    "    os.remove(file)\n",
    "print (f\"Removed {len(files_to_remove)} empty .sas files.\")\n",
    "print (f\"Kept {len(file_good)} good .sas files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc32c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks not completed problems if they have actually been processed, sometimes a problem goes NC because of an unrelated error or abort\n",
    "\n",
    "import os\n",
    "\n",
    "# Read and deduplicate problem names\n",
    "nc_file = \"not_completed/not_completed_problems.txt\"\n",
    "with open(nc_file, \"r\") as f:\n",
    "    nc_problem_names = list(set(line.strip() for line in f))\n",
    "\n",
    "print(f\"Total unique problems listed: {len(nc_problem_names)}\")\n",
    "\n",
    "solutions_path = \"./solutions\"\n",
    "\n",
    "# Check existence of files\n",
    "problems_actually_nc = []\n",
    "to_remove_already_have = []\n",
    "to_remove_actually_solved = []\n",
    "to_remove_never_processed = []\n",
    "\n",
    "for problem in nc_problem_names:\n",
    "    has_sas = os.path.exists(os.path.join(solutions_path, f\"{problem}_output.sas\"))\n",
    "    has_sol = os.path.exists(os.path.join(solutions_path, f\"{problem}.SOL\"))\n",
    "\n",
    "    if has_sas and not has_sol:\n",
    "        problems_actually_nc.append(problem)\n",
    "    elif has_sol and not has_sas:\n",
    "        to_remove_already_have.append(problem)\n",
    "    elif has_sas and has_sol:\n",
    "        to_remove_actually_solved.append(problem)\n",
    "    elif not has_sas and not has_sol:\n",
    "        to_remove_never_processed.append(problem)    \n",
    "    else:\n",
    "        problems_actually_nc.append(problem)\n",
    "\n",
    "# Output results\n",
    "print(f\"Problems with no matches (sas or sol), never processed: {len(to_remove_never_processed)}\")\n",
    "print(f\"Problems with sol but no sas, to remove: {len(to_remove_already_have)}\")\n",
    "print(f\"Problems with both sas and sol, to remove: {len(to_remove_actually_solved)}\")\n",
    "print(f\"Problems that are actually not completed: {len(problems_actually_nc)}\")\n",
    "\n",
    "# to fix nc list write to file\n",
    "# string_to_write =\"\"\n",
    "\n",
    "# for p in problems_actually_nc:\n",
    "#     string_to_write+=f\"{p}\\n\"\n",
    "\n",
    "# with open(nc_file, \"w\") as f:\n",
    "#     f.write(string_to_write.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f32628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear older log files leaving only the newest .txt and .err.txt per problem\n",
    "\n",
    "import os, re\n",
    "from collections import defaultdict\n",
    "\n",
    "logs_folder = \"logs\"\n",
    "\n",
    "# Updated regex: the entire string inside { } becomes the problem name (e.g. \"p34142_3\")\n",
    "pattern = re.compile(\n",
    "    r'^logs_script_\\d+_plan\\{(?P<problem>[^}]+)\\.pddl\\}(?P<err>\\.err)?\\.txt$'\n",
    ")\n",
    "\n",
    "# Build a dict mapping each problem name to the list of associated log files.\n",
    "problem_files = defaultdict(list)\n",
    "\n",
    "for fname in os.listdir(logs_folder):\n",
    "    m = pattern.match(fname)\n",
    "    if m:\n",
    "        problem = m.group(\"problem\")\n",
    "        problem_files[problem].append(fname)\n",
    "\n",
    "# For each problem, determine the newest plain log file and keep its pair (.err.txt if exists)\n",
    "files_to_keep = set()\n",
    "\n",
    "for problem, files in problem_files.items():\n",
    "    # Filter out plain log files (exclude those ending with \".err.txt\")\n",
    "    plain_logs = [f for f in files if not f.endswith(\".err.txt\")]\n",
    "    if not plain_logs:\n",
    "        # If no plain log exists, use the available files\n",
    "        plain_logs = files\n",
    "    # Pick the plain log file with the most recent modification time\n",
    "    ref_file = plain_logs[0]\n",
    "    newest_time = os.path.getctime(os.path.join(logs_folder, ref_file))\n",
    "    for f in plain_logs[1:]:\n",
    "        mtime = os.path.getctime(os.path.join(logs_folder, f))\n",
    "        if mtime > newest_time:\n",
    "            newest_time = mtime\n",
    "            ref_file = f\n",
    "    files_to_keep.add(ref_file)\n",
    "    # If an error log exists for this run, keep it too.\n",
    "    err_candidate = ref_file.replace(\".txt\", \".err.txt\")\n",
    "    if err_candidate in files:\n",
    "        files_to_keep.add(err_candidate)\n",
    "    # If the reference file is an error log, also consider its plain log.\n",
    "    if ref_file.endswith(\".err.txt\"):\n",
    "        plain_candidate = ref_file.replace(\".err.txt\", \".txt\")\n",
    "        if plain_candidate in files:\n",
    "            files_to_keep.add(plain_candidate)\n",
    "\n",
    "files_to_keep = list(files_to_keep)\n",
    "print(f\"Keeping {len(files_to_keep)} log files out of {len(os.listdir(logs_folder))} total files.\")\n",
    "\n",
    "# Remove files not in the newest set for each problem.\n",
    "# for fname in os.listdir(logs_folder):\n",
    "#     if pattern.match(fname) and fname not in files_to_keep:\n",
    "#         os.remove(os.path.join(logs_folder, fname))\n",
    "#         # print(f\"Removed log file: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take organized solution, create a class to represent a plan with initial state, actions and goals\n",
    "#we have to start by iteratining on the organized solutions we have, and search the corrisponding problem pddl file in the original dataset folder to extract initial state\n",
    "#actions can be taken from the .SOL file\n",
    "\n",
    "#\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "class Plan:\n",
    "    def __init__(self, problem_id, problem_full_name, initial_state, actions, goals, recognizability_class):\n",
    "        self.problem_id = problem_id\n",
    "        self.problem_full_name = problem_full_name\n",
    "        self.initial_state = initial_state\n",
    "        self.actions = actions\n",
    "        self.goals = goals\n",
    "        self.recognizability_class = recognizability_class\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Plan(problem_id={self.problem_id},\\n\"\n",
    "                f\"     problem_full_name={self.problem_full_name},\\n\"\n",
    "                f\"     initial_state={self.initial_state},\\n\"\n",
    "                f\"     actions={self.actions},\\n\"\n",
    "                f\"     goals={self.goals},\\n\"\n",
    "                f\"     recognizability_class={self.recognizability_class})\")\n",
    "\n",
    "def parse_pddl(pddl_file_path):\n",
    "    \"\"\"\n",
    "    Parses a PDDL file to extract initial state and goals.\n",
    "    This simple parser iterates through the file line by line.\n",
    "    \"\"\"\n",
    "    initial_state = []\n",
    "    goals = []\n",
    "    mode = None\n",
    "    try:\n",
    "        with open(pddl_file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line_stripped = line.strip()\n",
    "                # Start of initial state block\n",
    "                if line_stripped.startswith(\"(:init\"):\n",
    "                    mode = \"init\"\n",
    "                    # If there is content on the same line\n",
    "                    remainder = line_stripped[len(\"(:init\"):].strip()\n",
    "                    if remainder and remainder != \"(\" and not remainder.startswith(\";\"):\n",
    "                        initial_state.append(remainder)\n",
    "                    continue\n",
    "                # Start of goal block\n",
    "                elif line_stripped.startswith(\"(:goal\"):\n",
    "                    mode = \"goal\"\n",
    "                    remainder = line_stripped[len(\"(:goal\"):].strip()\n",
    "                    # Handle goal starting with (and ... if needed\n",
    "                    if remainder.startswith(\"(and\"):\n",
    "                        remainder = remainder[len(\"(and\"):].strip()\n",
    "                        if remainder and remainder != \"(\" and not remainder.startswith(\";\"):\n",
    "                            goals.append(remainder)\n",
    "                    continue\n",
    "                # End of a block\n",
    "                elif line_stripped == \")\" or line_stripped == \")))\":\n",
    "                    mode = None\n",
    "                    continue\n",
    "\n",
    "                # Append lines based on current block\n",
    "                if mode == \"init\":\n",
    "                    if line_stripped and not line_stripped.startswith(\";\"):\n",
    "                        initial_state.append(line_stripped)\n",
    "                elif mode == \"goal\":\n",
    "                    if line_stripped and not line_stripped.startswith(\";\"):\n",
    "                        goals.append(line_stripped)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing PDDL file {pddl_file_path}: {e}\")\n",
    "        raise Exception\n",
    "    return initial_state, goals\n",
    "\n",
    "def parse_sol(sol_file_path):\n",
    "    \"\"\"\n",
    "    Parses a SOL file to extract the list of actions.\n",
    "    Skips commented lines.\n",
    "    \"\"\"\n",
    "    actions = []\n",
    "    try:\n",
    "        with open(sol_file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line_stripped = line.strip()\n",
    "                # Skip comments (lines starting with ;)\n",
    "                if line_stripped.startswith(\";\") or not line_stripped:\n",
    "                    continue\n",
    "                line_stripped = line_stripped.replace(\"(\",\"\").replace(\")\",\"\")\n",
    "                actions.append(line_stripped)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing SOL file {sol_file_path}: {e}\")\n",
    "    return actions\n",
    "\n",
    "def main():\n",
    "    # Base directories for organized solutions and dataset PDDL files.\n",
    "    # Assumes the script is run from /home/rsignoroni/fastdownward_docker/\n",
    "    solutions_organized_dir = \"./solutions_organized\"\n",
    "    dataset_pddl_base = \"./logistics/\"  # adjust as needed\n",
    "\n",
    "    plans = []\n",
    "\n",
    "    # Iterate over each problem directory inside solutions_organized\n",
    "    for problem in os.listdir(solutions_organized_dir):\n",
    "        problem_dir = os.path.join(solutions_organized_dir, problem)\n",
    "        if not os.path.isdir(problem_dir):\n",
    "            continue\n",
    "\n",
    "        sols_dir = os.path.join(problem_dir, \"sols\")\n",
    "        if not os.path.exists(sols_dir):\n",
    "            print(f\"No 'sols' directory for problem {problem} in organized solutions.\")\n",
    "            continue\n",
    "\n",
    "        # For simplicity, pick the first SOL file we find\n",
    "        sol_files = [f for f in os.listdir(sols_dir) if f.upper().endswith(\".SOL\")]\n",
    "        if not sol_files:\n",
    "            print(f\"No SOL files found in {sols_dir}\")\n",
    "            continue\n",
    "\n",
    "        for sol_file in sol_files:\n",
    "            sol_file_path = os.path.join(sols_dir, sol_file)\n",
    "            actions = parse_sol(sol_file_path)\n",
    "\n",
    "            # Determine the corresponding PDDL file.\n",
    "            # Eg: logistics/0-0.2/p000146/p000146_0.pddl\n",
    "            pddl_file_path = None\n",
    "            problem_name = sol_file.split(\".\")[0]  # Extract the base problem name\n",
    "            for folder in [\"0-0.2\", \"0.2-0.4\", \"0.4-0.6\", \"0.6-0.8\", \"0.8-1.0\"]:\n",
    "                candidate_path = os.path.join(dataset_pddl_base, folder, problem, f\"{problem_name}.pddl\")\n",
    "                if os.path.exists(candidate_path):\n",
    "                    pddl_file_path = candidate_path\n",
    "                    recognizability_class = folder\n",
    "                break\n",
    "            if pddl_file_path is None:\n",
    "                print(f\"PDDL file not found for problem {problem} in any subfolder.\")\n",
    "                continue\n",
    "\n",
    "            initial_state, goals = parse_pddl(pddl_file_path)\n",
    "\n",
    "            # Create a Plan object and add to the list.\n",
    "            plan = Plan(problem_id=problem.split(\"_\")[0], problem_version=problem, initial_state=initial_state, actions=actions, goals=goals, recognizability_class=recognizability_class)\n",
    "            plans.append(plan)\n",
    "\n",
    "    # Print out all collected plans\n",
    "    for plan in plans:\n",
    "        print(plan)\n",
    "        print(\"=\" * 40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9909c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "#used to rename original .SOL files to have _og.SOL suffix\n",
    "\n",
    "import os\n",
    "sol_folder = './solutions'\n",
    "\n",
    "for file in os.listdir(sol_folder):\n",
    "    if \"_\" not in file:\n",
    "        name = file.split(\".\")[0]\n",
    "        new_name = f\"{name}_og.SOL\"\n",
    "        os.rename(os.path.join(sol_folder,file), os.path.join(sol_folder,new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e84293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searches trough the sas files for the time taken by problems, and saves them\n",
    "import os\n",
    "import re\n",
    "\n",
    "solutions_path = \"solutions\"\n",
    "matching_problems = []\n",
    "\n",
    "for filename in os.listdir(solutions_path):\n",
    "    if not filename.endswith(\"_output.sas\"):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(solutions_path, filename)\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if not lines:\n",
    "        continue\n",
    "\n",
    "    last_line = lines[-1].strip()\n",
    "    match = re.search(r'Time taken: (\\d+(?:\\.\\d+)?)', last_line)\n",
    "\n",
    "    if match:\n",
    "        time_taken = float(match.group(1))\n",
    "        if 3600 < time_taken < 7200: #adjust as needed to filter times\n",
    "            problem_name = filename.replace(\"_output.sas\", \"\")\n",
    "            matching_problems.append((problem_name, time_taken))\n",
    "\n",
    "# Output results\n",
    "print(f\"Problems sorted by time taken: {len(matching_problems)}\\n\")\n",
    "for problem, time_taken in sorted(matching_problems, key=lambda x: x[1]):\n",
    "    print(f\"{problem}: {time_taken:.2f} seconds\")\n",
    "    \n",
    "#saves the problems to file\n",
    "output_file = \"test_results/matching_problems.txt\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    for problem, time_taken in sorted(matching_problems, key=lambda x: x[1]):\n",
    "        f.write(f\"{problem}: {time_taken:.2f} seconds\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
